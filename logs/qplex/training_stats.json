{
  "mean_episode_reward": 497.55263157894734,
  "std_episode_reward": 148.45585864747477,
  "mean_episode_length": 1946.4736842105262,
  "mean_loss": 18824765814.912,
  "mean_q_values": 0.8348721227496863,
  "mean_td_error": 1.0453761401176453,
  "mean_epsilon": 0.16951360494497147,
  "timestep": 78001,
  "episode_count": 38,
  "buffer_size": 10000
}